{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1 answer\n",
        "\n",
        "In the context of predicting house prices based on characteristics like location, square footage, number of bedrooms, etc., several regression metrics can be employed to evaluate the performance of your Support Vector Machine (SVM) regression model. The choice of the best metric depends on the specific goals and requirements of your project. Here are some common regression metrics to consider:\n",
        "\n",
        "1. Mean Absolute Error (MAE):\n",
        "\n",
        "MAE measures the average absolute difference between the predicted and actual house prices. It gives you a sense of the average magnitude of errors in your predictions.\n",
        "Use MAE when you want to know the average dollar amount by which your predictions differ from the actual prices. MAE is relatively easy to interpret."
      ],
      "metadata": {
        "id": "CJra_fMJR5ZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "mae = mean_absolute_error(y_true, y_pred)\n"
      ],
      "metadata": {
        "id": "IUdpBiekSCFt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Mean Squared Error (MSE):\n",
        "\n",
        "MSE calculates the average of the squared differences between predicted and actual house prices. It emphasizes larger errors more than MAE since errors are squared.\n",
        "Use MSE when you want to penalize larger errors more than smaller ones. However, note that MSE is sensitive to outliers."
      ],
      "metadata": {
        "id": "w0eJ_LdiR-Fc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2t1DO6NqRzYf"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Root Mean Squared Error (RMSE):\n",
        "\n",
        "RMSE is the square root of MSE. It provides an estimate of the average absolute error in the same units as the target variable (e.g., dollars in this case).\n",
        "RMSE is widely used and is helpful when you want a metric that is more interpretable than MSE but still accounts for larger errors."
      ],
      "metadata": {
        "id": "OUgbXNgZSKPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n"
      ],
      "metadata": {
        "id": "Sxyq7xqqSOlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. . Median Absolute Error (MedAE):\n",
        "\n",
        "MedAE is the median of the absolute differences between predicted and actual prices. It is robust to outliers and can provide a more stable estimate of error when dealing with skewed data.\n",
        "Use MedAE when your dataset contains outliers and you want a more robust measure of central error tendency."
      ],
      "metadata": {
        "id": "IwUb9ev8SSyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import median_absolute_error\n",
        "medae = median_absolute_error(y_true, y_pred)\n"
      ],
      "metadata": {
        "id": "617KXT74SWo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Mean Absolute Percentage Error (MAPE):\n",
        "\n",
        "MAPE calculates the average percentage difference between predicted and actual prices relative to the actual prices. It measures the relative error.\n",
        "Use MAPE when you want to understand the percentage error in your predictions, which can be helpful for interpreting the magnitude of errors in a percentage format."
      ],
      "metadata": {
        "id": "xmDJfd-SSaPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "mape = mean_absolute_percentage_error(y_true, y_pred)\n"
      ],
      "metadata": {
        "id": "aiRBH6wpSdbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 answer\n",
        "\n",
        "If your goal is to predict the actual price of a house as accurately as possible, then the Mean Squared Error (MSE) would be the more appropriate evaluation metric to use in Python.\n",
        "\n",
        "Here's why:\n",
        "\n",
        "1. Mean Squared Error (MSE): MSE measures the average of the squared differences between the predicted and actual house prices. It heavily penalizes larger errors, giving them more weight. In the context of house price prediction, accuracy in terms of magnitude matters because even a small difference in predicted and actual prices can have a significant financial impact for both buyers and sellers."
      ],
      "metadata": {
        "id": "EQF20nwGSrE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(y_true, y_pred)\n"
      ],
      "metadata": {
        "id": "qSS5tBajTJ0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. R-squared (RÂ²): R-squared measures the proportion of the variance in the target variable that is explained by your model. While R-squared provides insights into how well your model explains the variance in house prices, it doesn't directly quantify the magnitude of prediction errors. A high R-squared value does not necessarily guarantee accurate price predictions."
      ],
      "metadata": {
        "id": "WDEP9cxBTM9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r_squared = r2_score(y_true, y_pred)\n"
      ],
      "metadata": {
        "id": "vkaflg16TQqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 answer\n",
        "\n",
        "When you have a dataset with a significant number of outliers and you want to select an appropriate regression metric to use with your SVM model in Python, you should prioritize metrics that are robust to outliers. Outliers can significantly affect the performance of traditional regression metrics like Mean Squared Error (MSE) or Root Mean Squared Error (RMSE). In such cases, the most appropriate metrics are:\n",
        "\n",
        "1. Median Absolute Error (MedAE):\n",
        "\n",
        "MedAE calculates the median of the absolute differences between predicted and actual values. It is robust to the influence of outliers and provides a more stable estimate of prediction error in the presence of extreme values.\n",
        "\n",
        "2. ean Absolute Percentage Error (MAPE):\n",
        "\n",
        "MAPE measures the average percentage difference between predicted and actual values relative to the actual values. It is less sensitive to outliers because it focuses on relative errors.\n",
        "\n",
        "3. Huber Loss:\n",
        "\n",
        "Huber loss combines the characteristics of both MSE and Mean Absolute Error (MAE). It is less sensitive to outliers than MSE but still provides a smooth and differentiable loss function for optimization.\n",
        "You can use Huber loss as a custom loss function when training your SVM regression model. Scikit-learn's SGDRegressor allows you to specify Huber loss through the loss parameter."
      ],
      "metadata": {
        "id": "jcZ0y2S3TT8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import median_absolute_error\n",
        "medae = median_absolute_error(y_true, y_pred)\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "mape = mean_absolute_percentage_error(y_true, y_pred)\n"
      ],
      "metadata": {
        "id": "zsabZytHT8N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 answer\n",
        "\n",
        "When you have built an SVM regression model using a polynomial kernel and calculated both Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) as evaluation metrics, and you find that both values are very close, it is generally a good practice to choose the simpler metric, which in this case is MSE.\n",
        "\n",
        "Here's why:\n",
        "\n",
        "1. Simplicity: MSE measures the average of the squared differences between predicted and actual values. RMSE is derived from MSE by taking the square root of the MSE. Therefore, MSE is a simpler metric as it provides a straightforward and interpretable measure of the average prediction error.\n",
        "\n",
        "2. Interpretability: MSE is in the same units as the target variable (e.g., dollars in the case of house prices), making it more interpretable. RMSE, on the other hand, has the same units as the target variable but in the square root form, which may not be as intuitive in some cases.\n",
        "\n",
        "3. Consistency: Since both MSE and RMSE are closely related (RMSE is essentially the square root of MSE), they generally yield consistent conclusions. If you find that MSE and RMSE are very close, it's an indication that the overall scale of the errors in your predictions is not too different, and either metric would provide a similar assessment of your model's performance.\n"
      ],
      "metadata": {
        "id": "H8xQaMe3T_tD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 answer\n",
        "\n",
        "When you are comparing the performance of different SVM regression models with various kernels (linear, polynomial, and RBF) and your goal is to measure how well the model explains the variance in the target variable, the most appropriate evaluation metric is R-squared (RÂ²).\n",
        "\n",
        "Here's why R-squared is suitable for this purpose:\n",
        "\n",
        "1. Explained Variance: R-squared measures the proportion of the variance in the target variable that is explained by your regression model. In other words, it quantifies how well your model captures and accounts for the variability in the target variable. A higher R-squared value indicates that the model explains a larger portion of the variance.\n",
        "\n",
        "2. Interpretability: R-squared values are easy to interpret. An R-squared of 1.0 means that the model perfectly explains all the variance, while an R-squared of 0.0 means that the model provides no explanatory power. Values between 0 and 1 indicate the proportion of variance explained.\n",
        "\n",
        "3. Comparative Metric: R-squared is a standardized metric that allows for a straightforward comparison between different models. When comparing SVM regression models with different kernels, R-squared helps you assess which kernel is better at explaining variance and, therefore, which one provides a better fit to your data."
      ],
      "metadata": {
        "id": "0JZYRCwHUvDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "r_squared = r2_score(y_true, y_pred)\n"
      ],
      "metadata": {
        "id": "dnQ0z0DrU-TZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}