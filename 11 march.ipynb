{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1 answer\n",
        "T-test:\n",
        "A t-test is used when you want to compare the means of two samples and determine if the observed differences between their means are statistically significant. T-tests are particularly useful when the sample size is small (typically less than 30) and when the population standard deviation is unknown.\n",
        "\n",
        "Z-test:\n",
        "A z-test is used to compare sample means to a known population mean when the population standard deviation is known. It's also used when the sample size is relatively large (typically greater than 30), as in this case, the sample mean is expected to be approximately normally distributed due to the Central Limit Theorem."
      ],
      "metadata": {
        "id": "3DBL_eJShxiB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGCoBO28httz",
        "outputId": "30c2f775-1416-42f8-ac44-4bf019d38b86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fail to reject the null hypothesis.there is no significant difference between the groups\n"
          ]
        }
      ],
      "source": [
        "# T- test\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "group1_scores =np.array([89,78,69,26,99])\n",
        "group2_scores =np.array([75,82,82,79,88])\n",
        "t_statistic,p_value = stats.ttest_ind(group1_scores,group2_scores)\n",
        "\n",
        "alpha=0.05\n",
        "if p_value < alpha:\n",
        "  print(\"reject the null hypothesis.there is a significant difference between the groups \")\n",
        "else:\n",
        "  print(\"fail to reject the null hypothesis.there is no significant difference between the groups\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# z test\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "historical_mean =175\n",
        "historical_stddev=8\n",
        "new_sample =np.array([178,182,170,174,179])\n",
        "z_score= (np.mean(new_sample)-historical_mean)/(historical_stddev/np.sqrt(len(new_sample)))\n",
        "alpha=0.05\n",
        "p_value=2*(1-stats.norm.cdf(np.abs(z_score)))\n",
        "if p_value<alpha:\n",
        "  print(\"reject the null hypthesis\")\n",
        "else:\n",
        "  print(\"fail to reject null hypothesis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN2rqQsMjSmA",
        "outputId": "8127ff86-363b-4464-82ce-c4c66adcaec0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fail to reject null hypothesis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 answer\n",
        "One-Tailed Test:\n",
        "In a one-tailed test, the critical region for determining statistical significance is concentrated in only one tail of the probability distribution curve. This type of test is used when the research hypothesis specifies a directional effect, meaning you are interested in whether the sample data is significantly greater than or less than a certain value.\n",
        "\n",
        "For example, if you're testing whether a new drug improves test scores and you expect it to increase scores, you'd use a one-tailed test. The critical region would be in the upper tail of the distribution.\n",
        "\n",
        "Two-Tailed Test:\n",
        "In a two-tailed test, the critical region for determining statistical significance is split between both tails of the probability distribution curve. This type of test is used when the research hypothesis doesn't specify a particular direction of the effect, and you are interested in whether the sample data is significantly different from a certain value.\n",
        "\n",
        "For example, if you're testing whether a coin is fair (equally likely to land heads or tails), a two-tailed test would be appropriate because you're interested in deviations from the expected value in both directions."
      ],
      "metadata": {
        "id": "zuqtUxYAkow4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 answer\n",
        "\n",
        "Type 1 Error (False Positive):\n",
        "A Type 1 error occurs when the null hypothesis is incorrectly rejected when it is actually true. In other words, you conclude that there is a significant effect or difference when there is none in the population. This error is also known as a \"false positive.\"\n",
        "\n",
        "Type 2 Error (False Negative):\n",
        "A Type 2 error occurs when the null hypothesis is incorrectly failed to be rejected when it is actually false. In other words, you fail to detect a significant effect or difference that actually exists in the population. This error is also known as a \"false negative.\""
      ],
      "metadata": {
        "id": "HRMmJMEyk5rR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# type 1 error\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "population=np.random.normal(200,20,1000)\n",
        "sample = np.random.normal(198,20,50)\n",
        "t_statistic,p_value=stats.ttest_1samp(sample,population.mean())\n",
        "alpha=0.05\n",
        "if p_value<alpha:\n",
        "  print(\"reject the null hypothesis\")\n",
        "else:\n",
        "  print(\"fail to reject null hypothesis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiam0lMNkqLn",
        "outputId": "7fc7e30e-9a06-4f17-ec85-da9035a4b5bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reject the null hypothesis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# type 2 error\n",
        "sample=np.random.normal(195,20,50)\n",
        "t_statistics,p_value=stats.ttest_1samp(sample,population.mean())\n",
        "alpha=0.05\n",
        "if p_value<alpha:\n",
        "  print(\"reject the null hypothesis\")\n",
        "else:\n",
        "  print(\"fail to reject the null hypothesis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O78o46ofkko3",
        "outputId": "8d17460f-8b3e-431d-b6ed-0188fccbfec8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reject the null hypothesis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 answer\n",
        "Bayes's Theorem is a fundamental concept in probability theory and statistics that describes how to update the probability of a hypothesis based on new evidence. It's a way of combining prior knowledge (prior probability) with new data to obtain a more informed probability (posterior probability). The theorem is named after the Reverend Thomas Bayes, who first introduced the idea.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ie4eQI75mqy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example  probability that a patient actually has the disease given a positive test result:\n",
        "P_A = 0.01\n",
        "P_B_given_A=0.95\n",
        "P_B_given_not_A=0.02\n",
        "\n",
        "P_B=P_B_given_A*P_A+P_B_given_not_A*(1-P_A)\n",
        "P_A_given_B=(P_B_given_A*P_A)/P_B\n",
        "print(\"probability of having the disease given a positive test result\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfKUc7remmN_",
        "outputId": "b3dd0459-71f0-4303-dfa5-5878c13fe60e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of having the disease given a positive test result\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 answer\n",
        "A confidence interval is a range of values that is likely to contain the true value of a population parameter (such as a mean or a proportion) with a certain level of confidence. It provides a measure of the uncertainty or margin of error associated with sample estimates.\n",
        "\n",
        "For example, if you calculate a 95% confidence interval for the mean height of a population, it means you are 95% confident that the true mean height falls within that interval.\n",
        "\n",
        "The formula to calculate a confidence interval depends on the distribution of the sample data and the parameter being estimated. For the mean of a normally distributed population, a common formula is:\n",
        "\n",
        "Confidence Interval\n",
        "=\n",
        "Sample Mean\n",
        "±\n",
        "Margin of Error\n",
        "Confidence Interval=Sample Mean±Margin of Error"
      ],
      "metadata": {
        "id": "iLHVJINuoWao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "data=np.array([175,152,126,189,174,175,198,179,182,125])\n",
        "confidence_level=0.95\n",
        "sample_mean=np.mean(data)\n",
        "sample_std=np.std(data,ddof=1)\n",
        "critical_value = stats.t.ppf((1 + confidence_level) / 2, df=len(data) - 1)\n",
        "margin_of_error = critical_value * (sample_std / np.sqrt(len(data)))\n",
        "confidence_interval=(sample_mean-margin_of_error,sample_mean+margin_of_error)\n",
        "print(\"Sample Mean:\",sample_mean)\n",
        "print(\"Margin of error:\",margin_of_error)\n",
        "print(\"Confidence Interval:\",confidence_interval)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20xt5fDfoYL4",
        "outputId": "e51b9988-65a4-4584-ed0d-b41da3b8f0e3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Mean: 167.5\n",
            "Margin of error: 17.937097941683472\n",
            "Confidence Interval: (149.56290205831652, 185.43709794168348)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 answer\n",
        "Suppose you have a biased coin that you suspect might be weighted in favor of heads. You want to calculate the probability that the coin is biased towards heads, given that you've flipped the coin 10 times and got heads 8 times."
      ],
      "metadata": {
        "id": "gurAbW17r_ZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_A=0.3\n",
        "P_B_given_A=0.8\n",
        "P_B_given_not_A=0.05\n",
        "P_B=P_B_given_A*P_A+P_B_given_not_A*(1-P_A)\n",
        "P_A_given_B=(P_B_given_A*P_A)/P_B\n",
        "print(\"probabilty that the coin is blessed towards heads given evidence:\",P_A_given_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv2eu5sArA3p",
        "outputId": "839880db-9fcc-4ebd-aa3a-f6a072ae4b4e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probabilty that the coin is blessed towards heads given evidence: 0.8727272727272728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 answer\n",
        "# 7 answer\n",
        "To calculate the 95% confidence interval for a sample of data with a known mean and standard deviation, you can use the formula:\n",
        "\n",
        "Confidence Interval\n",
        "=\n",
        "Sample Mean\n",
        "±\n",
        "Margin of Error\n",
        "Confidence Interval=Sample Mean±Margin of Error"
      ],
      "metadata": {
        "id": "kZYKOKERtHPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_mean=50\n",
        "population_stddev=5\n",
        "confidence_level=0.95\n",
        "from scipy.stats import norm\n",
        "z_critical=norm.ppf((1+confidence_level)/2)\n",
        "margin_of_error =z_critical*(population_stddev/(1**0.5))\n",
        "confidence_interval=(sample_mean-margin_of_error,sample_mean+margin_of_error)\n",
        "print(\"sample Mean:\",sample_mean)\n",
        "print(\"confidence Interval\",confidence_interval)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMF7-12As3aL",
        "outputId": "435f2ba9-75aa-466c-eda4-8c5e8772ebcc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample Mean: 50\n",
            "confidence Interval (40.200180077299734, 59.799819922700266)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8 answer\n",
        "The margin of error in a confidence interval is a measure of how much the sample estimate (such as the sample mean) is expected to vary from the true population parameter (such as the population mean) due to random sampling variability. It represents the range within which we expect the true parameter to fall with a certain level of confidence. A smaller margin of error indicates greater precision in our estimate.\n",
        "\n",
        "The margin of error is influenced by three main factors:\n",
        "\n",
        "Confidence Level: A higher confidence level results in a wider margin of error because we are more certain about the coverage of the interval.\n",
        "Sample Standard Deviation: A higher standard deviation increases the margin of error since the data points are more spread out.\n",
        "Sample Size: A larger sample size decreases the margin of error because a larger sample provides more information about the population, leading to a more precise estimate.\n",
        "Sample Size and Margin of Error:\n",
        "As the sample size increases, the margin of error decreases. This is because larger sample sizes provide more data points that better represent the population, leading to a more accurate estimate"
      ],
      "metadata": {
        "id": "WZMQsWvcubg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "population_proportion=0.6\n",
        "confidence_level=0.95\n",
        "sample_size_small=200\n",
        "standard_error_small=np.sqrt((population_proportion*(1 - population_proportion)) / sample_size_small)\n",
        "margin_of_error_small = norm.ppf((1 + confidence_level) / 2) * standard_error_small\n",
        "sample_size_large=1000\n",
        "standard_error_large=np.sqrt((population_proportion*(1-population_proportion))/sample_size_large)\n",
        "margin_of_error_large = norm.ppf((1 + confidence_level) / 2) * standard_error_large\n",
        "print(\"Margin of error(small sample):\",margin_of_error_small)\n",
        "print(\"margin of Error(Large sample):\",margin_of_error_large)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSVvnxHXujN4",
        "outputId": "bc7504cb-931f-4e16-b85b-50c312aeff67"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Margin of error(small sample): 0.06789514404457031\n",
            "margin of Error(Large sample): 0.03036363148515984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9 answer\n",
        "The z-score (also known as the standard score) measures how many standard deviations a data point is away from the mean of the population"
      ],
      "metadata": {
        "id": "iOvg3IJow0Nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_point = 95\n",
        "population_mean = 79\n",
        "population_stddev = 5\n",
        "\n",
        "z_score = (data_point - population_mean) / population_stddev\n",
        "\n",
        "print(\"Z-Score:\", z_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTMMA0m3wD34",
        "outputId": "ecfbd1b3-7b3c-4d53-c860-d527ff634bce"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z-Score: 3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10 answer\n",
        "To conduct a hypothesis test using a t-test, you need to set up the null and alternative hypotheses, calculate the test statistic, and compare it to the critical value to make a decision. In this case, you're testing whether the new weight loss drug is significantly effective."
      ],
      "metadata": {
        "id": "CUo6En5KxMi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "sample_mean=6\n",
        "sample_stddev=2.5\n",
        "sample_size=50\n",
        "confidence_level=0.95\n",
        "alpha=1-confidence_level\n",
        "hypothesized_mean=0\n",
        "t_statistic=(sample_mean-hypothesized_mean)/(sample_stddev/np.sqrt(sample_size))\n",
        "degree_of_freedom=sample_size-1\n",
        "critical_value=stats.t.ppf(alpha,df=degree_of_freedom)\n",
        "if t_statistic<critical_value:\n",
        "  print(\"reject the null hypothesis\")\n",
        "else:\n",
        "  print(\"fail to reject null hypothesis\")"
      ],
      "metadata": {
        "id": "_PLlmkEPxOUi",
        "outputId": "cecdb980-3e25-435e-cae9-c3b8129b85d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fail to reject null hypothesis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11 answer\n",
        "To calculate the 95% confidence interval for the true proportion of people who are satisfied with their job"
      ],
      "metadata": {
        "id": "Dvj97t4Iy2Fo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "sample_proportion=0.65\n",
        "sample_size=500\n",
        "confidence_level=0.95\n",
        "z_critical=norm.ppf((1+confidence_level)/2)\n",
        "margin_of_error=z_critical*np.sqrt((sample_proportion*(1-sample_proportion))/sample_size)\n",
        "confidence_interval=(sample_proportion-margin_of_error,sample_proportion+margin_of_error)\n",
        "print(\"sample proportion:\",sample_proportion)\n",
        "print(\"confidence Interval:\",confidence_interval)"
      ],
      "metadata": {
        "id": "2JJGNuFry7mF",
        "outputId": "fc069eb2-eabd-488b-bcf2-476323d542fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample proportion: 0.65\n",
            "confidence Interval: (0.6081925393809212, 0.6918074606190788)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12 answer\n"
      ],
      "metadata": {
        "id": "u3rKBWJH1Axd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "\n",
        "sample_mean_A = 85\n",
        "sample_stddev_A = 6\n",
        "sample_size_A = 30\n",
        "\n",
        "sample_mean_B = 82\n",
        "sample_stddev_B = 5\n",
        "sample_size_B = 25\n",
        "\n",
        "confidence_level = 0.95\n",
        "alpha = 1 - confidence_level\n",
        "\n",
        "\n",
        "pooled_stddev = np.sqrt(((sample_size_A - 1) * sample_stddev_A**2 + (sample_size_B - 1) * sample_stddev_B**2) / (sample_size_A + sample_size_B - 2))\n",
        "\n",
        "\n",
        "t_statistic = (sample_mean_A - sample_mean_B) / (pooled_stddev * np.sqrt((1/sample_size_A) + (1/sample_size_B)))\n",
        "\n",
        "\n",
        "degrees_of_freedom = sample_size_A + sample_size_B - 2\n",
        "\n",
        "\n",
        "critical_value = stats.t.ppf(1 - alpha/2, df=degrees_of_freedom)\n",
        "\n",
        "\n",
        "if np.abs(t_statistic) > critical_value:\n",
        "  print(\"Reject the null hypothesis. The two teaching methods have a significant difference.\")\n",
        "else:\n",
        "  print(\"Fail to Reject null hypothesis.no significant difference\")\n",
        "\n"
      ],
      "metadata": {
        "id": "RFK2HTWw1Dmg",
        "outputId": "1ddfc880-e651-4300-e13a-5dbcd72a4573",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fail to Reject null hypothesis.no significant difference\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13 answer"
      ],
      "metadata": {
        "id": "zJkNl_Gw3FQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sample_mean = 65\n",
        "population_mean = 60\n",
        "population_stddev = 8\n",
        "sample_size = 50\n",
        "confidence_level = 0.90\n",
        "critical_value = 1.645\n",
        "margin_of_error = critical_value * (population_stddev / np.sqrt(sample_size))\n",
        "confidence_interval = (sample_mean - margin_of_error, sample_mean + margin_of_error)\n",
        "print(\"Sample Mean:\", sample_mean)\n",
        "print(\"Confidence Interval:\", confidence_interval)\n"
      ],
      "metadata": {
        "id": "F7813Nfz2JM1",
        "outputId": "e71051af-112c-4044-c605-7dbaa7121c62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Mean: 65\n",
            "Confidence Interval: (63.13889495191701, 66.86110504808299)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14 answer\n"
      ],
      "metadata": {
        "id": "NbSPF99C3JMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "sample_mean = 0.25\n",
        "sample_stddev = 0.05\n",
        "sample_size = 30\n",
        "confidence_level = 0.90\n",
        "alpha = 1 - confidence_level\n",
        "hypothesized_mean = 0.30\n",
        "t_statistic = (sample_mean - hypothesized_mean) / (sample_stddev / np.sqrt(sample_size))\n",
        "degrees_of_freedom = sample_size - 1\n",
        "critical_value = stats.t.ppf(1 - alpha / 2, df=degrees_of_freedom)\n",
        "if abs(t_statistic) > critical_value:\n",
        "    print(\"Reject the null hypothesis. Caffeine has a significant effect on reaction time.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. No significant effect of caffeine on reaction time.\")\n"
      ],
      "metadata": {
        "id": "X4FJ_OOO3Cxr",
        "outputId": "2b3887bd-f2a1-45e9-bbe7-bf3f22aa69e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reject the null hypothesis. Caffeine has a significant effect on reaction time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GoAdTl5H3lEP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}