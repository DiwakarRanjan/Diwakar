{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XtgJvwp95x0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 answer\n",
        "\n",
        "Since I can't directly execute code here, I'll guide you through how you can perform these experiments using DCGAN (Deep Convolutional Generative Adversarial Network) in Python with TensorFlow and Keras, and then plot the losses to assess convergence.\n",
        "\n",
        "First, ensure you have TensorFlow and Keras installed. You can install them via pip if you haven't already:"
      ],
      "metadata": {
        "id": "T30tuNPw-kbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow keras"
      ],
      "metadata": {
        "id": "D4MthLjG-nl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A. Generating Images using DCGAN on CIFAR-10:\n",
        "1. Load CIFAR-10 Dataset:\n",
        "\n",
        "Load the CIFAR-10 dataset using TensorFlow's built-in dataset or any other method you prefer.\n",
        "2. Preprocess Data:\n",
        "\n",
        "Preprocess the images by scaling them to the range [-1, 1] (DCGAN's generator typically uses tanh activation in the output layer).\n",
        "You may also need to resize the images to match the input size expected by the generator.\n",
        "3. Define the Generator and Discriminator Models:\n",
        "\n",
        "Implement the generator and discriminator networks using convolutional layers.\n",
        "Use techniques such as batch normalization and LeakyReLU activations in both networks.\n",
        "4. Compile the Models:\n",
        "\n",
        "Compile both the generator and discriminator models using appropriate optimizers and loss functions.\n",
        "5. Train the GAN:\n",
        "\n",
        "Train the GAN by alternately training the discriminator and generator networks.\n",
        "For each training iteration, feed random noise to the generator and train the discriminator with real and fake images.\n",
        "Update the generator to generate more realistic images that fool the discriminator.\n",
        "6. Generate Images:\n",
        "\n",
        "Once training is complete, use the trained generator to generate synthetic images from random noise.\n",
        "B. Plotting Generator and Discriminator Losses:\n",
        "1. During Training:\n",
        "\n",
        "Keep track of the generator and discriminator losses at each training iteration.\n",
        "These losses are typically logged or stored in a list or array.\n",
        "2. Plotting Losses:\n",
        "\n",
        "After training, use a plotting library like Matplotlib to plot the generator and discriminator losses over time (number of training iterations or epochs).\n",
        "Plotting these losses on the same graph allows you to visualize the adversarial training process.\n",
        "3. Assessing Convergence:\n",
        "\n",
        "Look for stabilization or convergence of the losses over time.\n",
        "Convergence typically occurs when the generator loss decreases while the discriminator loss stabilizes, indicating that the generator is producing realistic images that are increasingly difficult for the discriminator to distinguish from real images."
      ],
      "metadata": {
        "id": "MPfm56SO-uLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have lists or arrays of generator and discriminator losses\n",
        "generator_losses = [...]  # List of generator losses\n",
        "discriminator_losses = [...]  # List of discriminator losses\n",
        "\n",
        "# Plot losses\n",
        "plt.figure()\n",
        "plt.plot(generator_losses, label='Generator Loss')\n",
        "plt.plot(discriminator_losses, label='Discriminator Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Generator and Discriminator Losses')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YjPY4tjY_Apd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 answer\n",
        "\n",
        "Sure, let's break down each part of the question:\n",
        "\n",
        "A. Training the Complete Network from Scratch:\n",
        "1. Load CIFAR-10 Dataset:\n",
        "\n",
        "Load the CIFAR-10 dataset using TensorFlow's built-in dataset or any other method.\n",
        "2. Prepare the ResNet50 Model:\n",
        "\n",
        "Load the ResNet50 model without the classification layer.\n",
        "Add a 2-layer neural network followed by a softmax layer for classification.\n",
        "3. Compile the Model:\n",
        "\n",
        "Compile the model with appropriate loss function (e.g., categorical cross-entropy) and optimizer (e.g., Adam).\n",
        "4. Train the Model:\n",
        "\n",
        "Train the entire model from scratch using the CIFAR-10 training data.\n",
        "Monitor accuracy on both the training and test sets over epochs.\n",
        "B. Fine-tuning Only the Neural Network Layers:\n",
        "1. Load Pre-trained ResNet50 Model:\n",
        "\n",
        "Load the pre-trained ResNet50 model with weights trained on ImageNet.\n",
        "2. Remove Top Classification Layer:\n",
        "\n",
        "Remove the top classification layer of the ResNet50 model.\n",
        "3. Add New Classification Layers:\n",
        "\n",
        "Add a 2-layer neural network followed by a softmax layer for classification on top of the ResNet50 base.\n",
        "4. Freeze ResNet50 Layers:\n",
        "\n",
        "Freeze the weights of all layers in the ResNet50 base to prevent them from being updated during training.\n",
        "5. Compile and Train the Model:\n",
        "\n",
        "Compile the model with appropriate loss function and optimizer.\n",
        "Train only the added classification layers using the CIFAR-10 training data.\n",
        "Monitor accuracy on both the training and test sets over epochs.\n",
        "C. Fine-tuning All Layers of the ResNet50 Model:\n",
        "1. Load Pre-trained ResNet50 Model:\n",
        "\n",
        "Load the pre-trained ResNet50 model with weights trained on ImageNet.\n",
        "2. Remove Top Classification Layer:\n",
        "\n",
        "Remove the top classification layer of the ResNet50 model.\n",
        "3. Add New Classification Layers:\n",
        "\n",
        "Add a 2-layer neural network followed by a softmax layer for classification on top of the ResNet50 base.\n",
        "4. Compile and Train the Model:\n",
        "\n",
        "Compile the model with appropriate loss function and optimizer.\n",
        "Fine-tune all layers of the model (including the ResNet50 base) using the CIFAR-10 training data.\n",
        "Monitor accuracy on both the training and test sets over epochs.\n",
        "D. Domain Adaptation Algorithm:\n",
        "For proposing a domain adaptation algorithm, consider techniques like domain adversarial training, where the model is trained to minimize a classification loss on the source domain (CIFAR-10) while simultaneously maximizing a domain confusion loss to make the feature representations domain-invariant. Alternatively, you could explore techniques like self-training or domain-specific data augmentation to improve model generalization to the target domain.\n",
        "\n",
        "The key to achieving better accuracy in domain adaptation lies in effectively leveraging additional data from other datasets (source domains) to enhance the model's ability to generalize to the target domain (CIFAR-10) while avoiding overfitting. Ensure that the proposed algorithm strikes a balance between exploiting the additional data and maintaining the model's ability to generalize across domains."
      ],
      "metadata": {
        "id": "91RxhnGj_ClA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 answer\n",
        "\n",
        "To implement a GAN from scratch using Keras to generate celebrity faces from noise using the CelebA dataset, follow these steps:\n",
        "\n",
        "1. Download and Preprocess the Data:\n",
        "\n",
        "Download the CelebA dataset from the provided link.\n",
        "Preprocess the images as necessary (e.g., resizing, normalization).\n",
        "2. Build the Generator Model:\n",
        "\n",
        "Create a generator model using Keras Sequential API.\n",
        "Start with a dense layer followed by reshape to a suitable shape.\n",
        "Use transposed convolutional layers (Conv2DTranspose) to upsample the input noise into a realistic image.\n",
        "3. Build the Discriminator Model:\n",
        "\n",
        "Create a discriminator model using Keras Sequential API.\n",
        "Use convolutional layers (Conv2D) to downsample the input image and classify it as real or fake.\n",
        "4. Compile the Models:\n",
        "\n",
        "Compile both the generator and discriminator models separately.\n",
        "Use binary cross-entropy loss for both models.\n",
        "5. Build the GAN Model:\n",
        "\n",
        "Combine the generator and discriminator models into a GAN model.\n",
        "Set the discriminator to be non-trainable during GAN training.\n",
        "6. Train the GAN:\n",
        "\n",
        "Write a training loop to train the GAN.\n",
        "Alternately train the generator and discriminator networks.\n",
        "Feed random noise to the generator and train the discriminator with real and fake images.\n",
        "Update the generator to generate more realistic images that fool the discriminator.\n",
        "7. Generate Images:\n",
        "\n",
        "Once training is complete, use the trained generator to generate synthetic images from random noise.\n",
        "8. Optional: Use Cases:\n",
        "\n",
        "Choose one or more use cases from the provided list (e.g., human face generation, super-resolution).\n",
        "Adapt the generator and discriminator architectures and training process as needed for the chosen use case.\n",
        "Remember to preprocess the CelebA dataset and adjust the architecture and training parameters based on your specific requirements and use case. Additionally, monitor the training process carefully, as training GANs can be challenging and may require experimentation with different hyperparameters and techniques to achieve good results."
      ],
      "metadata": {
        "id": "dTSwFQM5A_pP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coding question\n",
        "\n"
      ],
      "metadata": {
        "id": "tRFlFGlHBQ9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 answer\n",
        "\n",
        "Below is a Python function that generates augmented data for training a GAN. This function takes an image dataset as input and applies data augmentation techniques commonly used in GAN training, such as random rotation, flipping, and cropping. It uses the PIL (Python Imaging Library) module to perform these augmentations. You can customize the augmentation parameters such as rotation angles, flip probability, and crop size according to your requirements:"
      ],
      "metadata": {
        "id": "8o6XCfaiBZwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def augment_data(images, rotation_range=10, flip_probability=0.5, crop_size=(128, 128)):\n",
        "    \"\"\"\n",
        "    Generate augmented data for GAN training.\n",
        "\n",
        "    Parameters:\n",
        "        images (list): List of input images (PIL Image objects).\n",
        "        rotation_range (int): Range of random rotation angles in degrees.\n",
        "        flip_probability (float): Probability of random horizontal flipping.\n",
        "        crop_size (tuple): Size of cropped region (height, width).\n",
        "\n",
        "    Returns:\n",
        "        augmented_images (list): List of augmented images (PIL Image objects).\n",
        "    \"\"\"\n",
        "    augmented_images = []\n",
        "\n",
        "    for img in images:\n",
        "        # Random rotation\n",
        "        angle = random.uniform(-rotation_range, rotation_range)\n",
        "        rotated_img = img.rotate(angle)\n",
        "\n",
        "        # Random horizontal flipping\n",
        "        if random.random() < flip_probability:\n",
        "            flipped_img = rotated_img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        else:\n",
        "            flipped_img = rotated_img\n",
        "\n",
        "        # Random cropping\n",
        "        width, height = flipped_img.size\n",
        "        left = random.randint(0, width - crop_size[1])\n",
        "        top = random.randint(0, height - crop_size[0])\n",
        "        right = left + crop_size[1]\n",
        "        bottom = top + crop_size[0]\n",
        "        cropped_img = flipped_img.crop((left, top, right, bottom))\n",
        "\n",
        "        augmented_images.append(cropped_img)\n",
        "\n",
        "    return augmented_images\n"
      ],
      "metadata": {
        "id": "bmZ8NYi2BmO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use this function to augment your dataset before training your GAN. Here's how you can use it:"
      ],
      "metadata": {
        "id": "2hW5t5d2Bp-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load images from dataset (example)\n",
        "images = [Image.open('image1.jpg'), Image.open('image2.jpg'), ...]\n",
        "\n",
        "# Augment data\n",
        "augmented_images = augment_data(images, rotation_range=15, flip_probability=0.5, crop_size=(128, 128))\n"
      ],
      "metadata": {
        "id": "k0VUJZi8BvK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 answer\n",
        "\n"
      ],
      "metadata": {
        "id": "G1DQenicBxUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_discriminator(input_shape):\n",
        "    \"\"\"\n",
        "    Build a simple discriminator model for binary classification.\n",
        "\n",
        "    Parameters:\n",
        "        input_shape (tuple): Shape of the input data (height, width, channels).\n",
        "\n",
        "    Returns:\n",
        "        discriminator (tf.keras.Model): Discriminator model.\n",
        "    \"\"\"\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Convolutional layers\n",
        "    model.add(layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=input_shape))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "\n",
        "    model.add(layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "\n",
        "    # Flatten layer\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Dense layer for classification\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage:\n",
        "input_shape = (28, 28, 1)  # Example input shape for MNIST-like images\n",
        "discriminator = build_discriminator(input_shape)\n",
        "discriminator.summary()\n"
      ],
      "metadata": {
        "id": "kPrr-uWbB7FK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 answer\n",
        "\n"
      ],
      "metadata": {
        "id": "urjoUqSPB7-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_generator(latent_dim):\n",
        "    \"\"\"\n",
        "    Build a generator model using transpose convolution.\n",
        "\n",
        "    Parameters:\n",
        "        latent_dim (int): Dimensionality of the latent space.\n",
        "\n",
        "    Returns:\n",
        "        generator (tf.keras.Model): Generator model.\n",
        "    \"\"\"\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Dense layer to map latent space to initial convolutional shape\n",
        "    model.add(layers.Dense(4 * 4 * 256, input_dim=latent_dim))\n",
        "    model.add(layers.Reshape((4, 4, 256)))\n",
        "\n",
        "    # Transpose convolutional layers\n",
        "    model.add(layers.Conv2DTranspose(128, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(3, kernel_size=(5, 5), strides=(2, 2), padding='same', activation='tanh'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage:\n",
        "latent_dim = 100  # Dimensionality of the latent space\n",
        "generator = build_generator(latent_dim)\n",
        "generator.summary()\n"
      ],
      "metadata": {
        "id": "5kRIHm3GCFMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 answer\n",
        "\n"
      ],
      "metadata": {
        "id": "i6OvvBsLCF_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def minimax_loss(real_output, fake_output):\n",
        "    \"\"\"\n",
        "    Calculate the Minimax loss for a GAN.\n",
        "\n",
        "    Parameters:\n",
        "        real_output (tf.Tensor): Output of the discriminator for real images.\n",
        "        fake_output (tf.Tensor): Output of the discriminator for fake images.\n",
        "\n",
        "    Returns:\n",
        "        generator_loss (tf.Tensor): Loss for the generator.\n",
        "        discriminator_loss (tf.Tensor): Loss for the discriminator.\n",
        "    \"\"\"\n",
        "    # Generator loss: minimize log(1 - D(G(z)))\n",
        "    generator_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "        labels=tf.ones_like(fake_output), logits=fake_output))\n",
        "\n",
        "    # Discriminator loss: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "    real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "        labels=tf.ones_like(real_output), logits=real_output))\n",
        "    fake_loss = tf.reduce_mean(tf.nn.sigmoid_cr\n"
      ],
      "metadata": {
        "id": "l-vdZ9t0CH6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function takes as input the output of the discriminator for real and fake images. It calculates the generator loss and discriminator loss using the Minimax loss formulation:\n",
        "\n",
        "Generator loss: It aims to minimize the log probability of the discriminator being able to correctly classify fake images as fake. This is equivalent to minimizing the cross-entropy between the discriminator's output for fake images and a tensor of ones (indicating that the images are real).\n",
        "\n",
        "Discriminator loss: It aims to maximize the log probability of the discriminator being able to correctly classify both real and fake images. This is equivalent to maximizing the cross-entropy between the discriminator's output for real images and a tensor of ones (indicating that the images are real), and between its output for fake images and a tensor of zeros (indicating that the images are fake).\n",
        "\n"
      ],
      "metadata": {
        "id": "AR6vVPiVCTyY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 answer\n",
        "\n"
      ],
      "metadata": {
        "id": "Ypuwa7nXCZz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "# Load CIFAR-10 dataset (example)\n",
        "(x_train, _), (_, _) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [-1, 1]\n",
        "x_train = (x_train.astype('float32') - 127.5) / 127.5\n",
        "\n",
        "# Define the dimensionality of the latent space\n",
        "latent_dim = 100\n",
        "\n",
        "# Build the generator\n",
        "generator = build_generator(latent_dim)\n",
        "\n",
        "# Build the discriminator\n",
        "discriminator = build_discriminator((32, 32, 3))\n",
        "\n",
        "# Compile the discriminator\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
        "\n",
        "# Freeze the discriminator's weights during GAN training\n",
        "discriminator.trainable = False\n",
        "\n",
        "# Build the GAN model\n",
        "gan_input = tf.keras.Input(shape=(latent_dim,))\n",
        "gan_output = discriminator(generator(gan_input))\n",
        "gan = tf.keras.Model(gan_input, gan_output)\n",
        "\n",
        "# Compile the GAN model\n",
        "gan.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
        "\n",
        "# Define a function to train the GAN\n",
        "def train_gan(x_train, epochs=50, batch_size=128, sample_interval=100):\n",
        "    for epoch in range(epochs):\n",
        "        # Sample random noise for the generator input\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "\n",
        "        # Generate fake images\n",
        "        generated_images = generator.predict(noise)\n",
        "\n",
        "        # Select a random batch of real images\n",
        "        idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
        "        real_images = x_train[idx]\n",
        "\n",
        "        # Concatenate real and fake images to create the training batch\n",
        "        X = np.concatenate([real_images, generated_images])\n",
        "\n",
        "        # Labels for real and fake images\n",
        "        y_real = np.ones((batch_size, 1))\n",
        "        y_fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the discriminator\n",
        "        d_loss_real = discriminator.train_on_batch(real_images, y_real)\n",
        "        d_loss_fake = discriminator.train_on_batch(generated_images, y_fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # Train the generator (via the GAN model)\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "        g_loss = gan.train_on_batch(noise, y_real)\n",
        "\n",
        "        # Print progress\n",
        "        if epoch % sample_interval == 0:\n",
        "            print(f'Epoch {epoch}, D Loss: {d_loss}, G Loss: {g_loss}')\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(x_train)\n"
      ],
      "metadata": {
        "id": "qa2Nci-cTf9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code:\n",
        "\n",
        "We load the CIFAR-10 dataset and normalize the pixel values to the range [-1, 1].\n",
        "We build the generator and discriminator models.\n",
        "We compile the discriminator and freeze its weights during GAN training.\n",
        "We connect the generator and discriminator to create the GAN model.\n",
        "We compile the GAN model.\n",
        "We define a function to train the GAN, where we alternate between training the discriminator and the generator. We print the discriminator and generator losses at regular intervals.\n",
        "Finally, we train the GAN model using the CIFAR-10 dataset."
      ],
      "metadata": {
        "id": "A-0LK3YJThQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 answer\n",
        "\n",
        "To implement transfer learning with GANs on the CIFAR-10 dataset, we will follow the steps outlined:\n",
        "\n",
        "Load a pre-trained convolutional neural network (CNN) model (e.g., VGG16 or ResNet) using a library like PyTorch or TensorFlow.\n",
        "Modify the model for GAN-based image generation by removing the fully connected layers.\n",
        "Implement a generator and discriminator network.\n",
        "Train the GAN using the pre-trained CNN as the feature extractor to improve the quality of generated images.\n",
        "Evaluate the performance of your GAN by generating sample images from random noise."
      ],
      "metadata": {
        "id": "2N-J0oIHTkva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models import resnet18\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load a pre-trained CNN model\n",
        "pretrained_model = resnet18(pretrained=True)\n",
        "\n",
        "# Step 2: Modify the model for GAN-based image generation by removing the fully connected layers\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, pretrained_model):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.features = nn.Sequential(*list(pretrained_model.children())[:-2])  # Remove fully connected layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# Step 3: Implement a generator and discriminator network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, feature_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.feature_dim = feature_dim\n",
        "        self.linear = nn.Linear(latent_dim, feature_dim)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv_transpose = nn.ConvTranspose2d(feature_dim, 3, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, z):\n",
        "        x = self.linear(z)\n",
        "        x = self.relu(x)\n",
        "        x = x.view(-1, self.feature_dim, 1, 1)\n",
        "        x = self.conv_transpose(x)\n",
        "        return torch.tanh(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, feature_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv = nn.Conv2d(512, feature_dim, kernel_size=1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc = nn.Linear(feature_dim * 8 * 8, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.relu(x)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = self.fc(x)\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # All dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "# Step 4: Train the GAN using the pre-trained CNN as the feature extractor\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Hyperparameters\n",
        "latent_dim = 100\n",
        "feature_dim = 512\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator(latent_dim, feature_dim).to(device)\n",
        "discriminator = Discriminator(feature_dim).to(device)\n",
        "feature_extractor = FeatureExtractor(pretrained_model).to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (real_images, _) in enumerate(train_loader):\n",
        "        real_images = real_images.to(device)\n",
        "        batch_size = real_images.size(0)\n",
        "\n",
        "        # Train discriminator with real images\n",
        "        optimizer_D.zero_grad()\n",
        "        real_features = feature_extractor(real_images)\n",
        "        real_outputs = discriminator(real_features.detach())\n",
        "        real_loss = criterion(real_outputs, torch.full((batch_size, 1), real_label, device=device))\n",
        "\n",
        "        # Train discriminator with fake images\n",
        "        z = torch.randn(batch_size, latent_dim, device=device)\n",
        "        fake_images = generator(z)\n",
        "        fake_features = feature_extractor(fake_images.detach())\n",
        "        fake_outputs = discriminator(fake_features)\n",
        "        fake_loss = criterion(fake_outputs, torch.full((batch_size, 1), fake_label, device=device))\n",
        "\n",
        "        discriminator_loss = real_loss + fake_loss\n",
        "        discriminator_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Train generator\n",
        "        optimizer_G.zero_grad()\n",
        "        fake_features = feature_extractor(fake_images)\n",
        "        outputs = discriminator(fake_features)\n",
        "        generator_loss = criterion(outputs, torch.full((batch_size, 1), real_label, device=device))\n",
        "        generator_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Epoch [{epoch}/{num_epochs}], Step [{i}/{len(train_loader)}], \"\n",
        "                  f\"Discriminator Loss: {discriminator_loss.item():.4f}, \"\n",
        "                  f\"Generator Loss: {generator_loss.item():.4f}\")\n",
        "\n",
        "# Step 5: Evaluate the performance of your GAN by generating sample images from random noise\n",
        "# Generate sample images\n",
        "with torch.no_grad():\n",
        "\n"
      ],
      "metadata": {
        "id": "CWydnJ4zTr7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 answer"
      ],
      "metadata": {
        "id": "8xpyLG73Tzab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the Generator network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, img_shape):\n",
        "        super(Generator, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_shape = img_shape\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, np.prod(img_shape)),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        img = img.view(img.size(0), *self.img_shape)\n",
        "        return img\n",
        "\n",
        "# Define the Discriminator network\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_shape):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.img_shape = img_shape\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(np.prod(img_shape), 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.size(0), -1)\n",
        "        validity = self.model(img_flat)\n",
        "        return validity\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(generator, discriminator, dataloader, num_epochs, latent_dim, img_shape, lr):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    generator.to(device)\n",
        "    discriminator.to(device)\n",
        "\n",
        "    # Loss function\n",
        "    adversarial_loss = nn.BCELoss()\n",
        "\n",
        "    # Optimizers\n",
        "    optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (imgs, _) in enumerate(dataloader):\n",
        "\n",
        "            # Adversarial ground truths\n",
        "            valid = torch.ones(imgs.size(0), 1).to(device)\n",
        "            fake = torch.zeros(imgs.size(0), 1).to(device)\n",
        "\n",
        "            # Configure input\n",
        "            real_imgs = imgs.type(torch.FloatTensor).to(device)\n",
        "\n",
        "            # -----------------\n",
        "            #  Train Generator\n",
        "            # -----------------\n",
        "\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            # Sample noise as generator input\n",
        "            z = torch.randn(imgs.size(0), latent_dim).to(device)\n",
        "\n",
        "            # Generate a batch of images\n",
        "            gen_imgs = generator(z)\n",
        "\n",
        "            # Loss measures generator's ability to fool the discriminator\n",
        "            g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
        "\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train Discriminator\n",
        "            # ---------------------\n",
        "\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            # Measure discriminator's ability to classify real from generated samples\n",
        "            real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
        "            fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
        "            d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print(\n",
        "                    \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "                    % (epoch, num_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
        "                )\n",
        "\n",
        "    return generator, discriminator\n",
        "\n",
        "# Function to generate sample images\n",
        "def generate_samples(generator, num_samples, latent_dim):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    generator.to(device)\n",
        "    generator.eval()\n",
        "\n",
        "    # Sample noise\n",
        "    z = torch.randn(num_samples, latent_dim).to(device)\n",
        "\n",
        "    # Generate a batch of images\n",
        "    with torch.no_grad():\n",
        "\n"
      ],
      "metadata": {
        "id": "656XcNLpT-S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8 answer\n",
        "\n",
        "\n",
        "let's create a Deep Convolutional Generative Adversarial Network (DCGAN) in TensorFlow/Keras to generate high-resolution images from low-resolution image datasets. DCGANs are known for their ability to generate high-quality images by leveraging deep convolutional networks. Here's how we can implement it:\n",
        "\n",
        "1. Generator Architecture:\n",
        "\n",
        "We'll use transposed convolutional layers (also known as deconvolution or fractionally-strided convolution) to upscale the input noise vector to the desired image size.\n",
        "We'll use batch normalization after each convolutional layer to stabilize and speed up training.\n",
        "ReLU activation functions will be used in the intermediate layers, except for the output layer, which will use Tanh to ensure the pixel values are in the range [-1, 1].\n",
        "2. Discriminator Architecture:\n",
        "\n",
        "We'll use convolutional layers to downscale the input image and classify whether it's real or fake.\n",
        "Similar to the generator, we'll use batch normalization after each convolutional layer.\n",
        "Leaky ReLU activation functions will be used in the intermediate layers, and a Sigmoid activation function will be used in the output layer to output a probability score.\n",
        "3. Training Process:\n",
        "\n",
        "The generator and discriminator will be trained alternately. The generator tries to generate realistic images to fool the discriminator, while the discriminator tries to distinguish between real and fake images.\n",
        "We'll use the binary cross-entropy loss function for both the generator and discriminator.\n",
        "Adam optimizer with a learning rate of 0.0002 and momentum beta_1=0.5 will be used for training."
      ],
      "metadata": {
        "id": "pZGeBqFvT_JE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "# Generator\n",
        "def build_generator(latent_dim):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, input_dim=latent_dim))\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    model.add(layers.Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "    model.add(layers.Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "    model.add(layers.Conv2DTranspose(1, kernel_size=3, strides=2, padding='same', activation='tanh'))\n",
        "    return model\n",
        "\n",
        "# Discriminator\n",
        "def build_discriminator():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(64, kernel_size=3, strides=2, padding='same', input_shape=(28, 28, 1)))\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "    model.add(layers.Conv2D(128, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "    model.add(layers.Conv2D(256, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# Define the DCGAN\n",
        "def build_dcgan(generator, discriminator):\n",
        "    discriminator.trainable = False\n",
        "    model = models.Sequential()\n",
        "    model.add(generator)\n",
        "    model.add(discriminator)\n",
        "    return model\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "(x_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
        "\n",
        "# Define the hyperparameters\n",
        "latent_dim = 100\n",
        "epochs = 50\n",
        "batch_size = 128\n",
        "\n",
        "# Build and compile the discriminator\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
        "\n",
        "# Build the generator\n",
        "generator = build_generator(latent_dim)\n",
        "\n",
        "# Build the DCGAN\n",
        "dcgan = build_dcgan(generator, discriminator)\n",
        "dcgan.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
        "\n",
        "# Train the DCGAN\n",
        "for epoch in range(epochs):\n",
        "    for batch in range(len(x_train) // batch_size):\n",
        "        # Train the discriminator\n",
        "        noise = tf.random.normal((batch_size, latent_dim))\n",
        "        fake_images = generator(noise)\n",
        "        real_images = x_train[batch * batch_size : (batch + 1) * batch_size]\n",
        "        x = tf.concat([real_images, fake_images], axis=0)\n",
        "        y = tf.constant([[1.0]] * batch_size + [[0.0]] * batch_size)\n",
        "        discriminator.trainable = True\n",
        "        d_loss = discriminator.train_on_batch(x, y)\n",
        "\n",
        "        # Train the generator\n",
        "        noise = tf.random.normal((batch_size, latent_dim))\n",
        "        y = tf.constant([[1.0]] * batch_size)\n",
        "        discriminator.trainable = False\n",
        "        g_loss = dcgan.train_on_batch(noise, y)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}, D Loss: {d_loss[0]}, G Loss: {g_loss}')\n",
        "\n",
        "# Generate some sample images\n",
        "num_samples = 10\n",
        "noise = tf.random.normal((num_samples, latent_dim))\n",
        "sample_images = generator(noise)\n",
        "\n",
        "# Plot the sample images\n",
        "plt.figure(figsize=(10, 1))\n",
        "for i in range(num_samples):\n",
        "    plt.subplot(1, num_samples, i+1)\n",
        "    plt.imshow(sample_images[i].numpy().reshape((28, 28)), cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rNqFYirmUHty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9 answer"
      ],
      "metadata": {
        "id": "WsPbTgiRUGKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess the Fashion MNIST dataset\n",
        "(x_train, y_train), (_, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "\n",
        "# Define the Generator network\n",
        "def build_generator(latent_dim, num_classes):\n",
        "    input_z = layers.Input(shape=(latent_dim,))\n",
        "    input_label = layers.Input(shape=(num_classes,))\n",
        "\n",
        "    x = layers.Concatenate()([input_z, input_label])\n",
        "    x = layers.Dense(7 * 7 * 128, activation='relu')(x)\n",
        "    x = layers.Reshape((7, 7, 128))(x)\n",
        "    x = layers.Conv2DTranspose(128, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2DTranspose(64, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
        "    output = layers.Conv2DTranspose(1, kernel_size=3, strides=2, padding='same', activation='sigmoid')(x)\n",
        "\n",
        "    return models.Model([input_z, input_label], output)\n",
        "\n",
        "# Define the Discriminator network\n",
        "def build_discriminator(num_classes):\n",
        "    input_img = layers.Input(shape=(28, 28, 1))\n",
        "    input_label = layers.Input(shape=(num_classes,))\n",
        "\n",
        "    x = layers.Conv2D(64, kernel_size=3, strides=2, padding='same', activation='relu')(input_img)\n",
        "    x = layers.Conv2D(128, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    concatenated = layers.Concatenate()([x, input_label])\n",
        "    x = layers.Dense(128, activation='relu')(concatenated)\n",
        "    output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    return models.Model([input_img, input_label], output)\n",
        "\n",
        "# Define the GAN\n",
        "def build_cgan(generator, discriminator):\n",
        "    noise = layers.Input(shape=(latent_dim,))\n",
        "    label = layers.Input(shape=(num_classes,))\n",
        "    img = generator([noise, label])\n",
        "    output = discriminator([img, label])\n",
        "    return models.Model([noise, label], output)\n",
        "\n",
        "# Define the hyperparameters\n",
        "latent_dim = 100\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "batch_size = 128\n",
        "\n",
        "# Build and compile the discriminator\n",
        "discriminator = build_discriminator(num_classes)\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
        "\n",
        "# Build the generator\n",
        "generator = build_generator(latent_dim, num_classes)\n",
        "\n",
        "# Build the cGAN\n",
        "cgan = build_cgan(generator, discriminator)\n",
        "cgan.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
        "\n",
        "# Train the cGAN\n",
        "for epoch in range(epochs):\n",
        "    for batch in range(len(x_train) // batch_size):\n",
        "        # Sample real images and labels\n",
        "        idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
        "        real_images, labels = x_train[idx], y_train[idx]\n",
        "\n",
        "        # Sample noise\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "\n",
        "        # Generate fake images\n",
        "        fake_images = generator.predict([noise, labels])\n",
        "\n",
        "        # Train the discriminator\n",
        "        d_loss_real = discriminator.train_on_batch([real_images, labels], np.ones((batch_size, 1)))\n",
        "        d_loss_fake = discriminator.train_on_batch([fake_images, labels], np.zeros((batch_size, 1)))\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # Train the generator\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "        valid_y = np.array([1] * batch_size)\n",
        "        g_loss = cgan.train_on_batch([noise, labels], valid_y)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}, D Loss: {d_loss[0]}, G Loss: {g_loss}')\n",
        "\n",
        "# Generate some sample images\n",
        "num_samples = 10\n",
        "noise = np.random.normal(0, 1, (num_samples, latent_dim))\n",
        "labels = np.eye(num_classes)[np.arange(num_samples) % num_classes]  # Generate different labels for each sample\n",
        "sample_images = generator.predict([noise, labels])\n",
        "\n",
        "# Plot the sample images\n",
        "plt.figure(figsize=(10, 1))\n",
        "for i in range(num_samples):\n",
        "    plt.subplot(1, num_samples, i+1)\n",
        "    plt.imshow(sample_images[i].reshape((28, 28)), cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "P1goSr9SVAqo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}